[logging]
identifier = xlmr_rec_mcl

[train] #train parameters
epoch = 60
batch_size = 64

[data] #data parameters
train_dataset_type = parallel_separate_dataset
train_formatter =  teacher_sim_formatter
teacher_path = /apdcephfs/share_1157269/karlding/modle_card/sentence-transformers_paraphrase-distilroberta-base-v1

[model] #model parameters
model_name = rec_mcl
student_model_path = /apdcephfs/share_1157269/karlding/modle_card/paraphrase-xlm-r-multilingual-v1
emb_ckp_path =  /apdcephfs/share_1157269/karlding/mul_output_train/logs_train/xlmr_alldata_albert_mse/2021_11_04__04_30_51/best_checkpoint_ep7.pth
repeat = 2
layers_to_keep = 6



[optim] #optimizer and lr_scheduler parameters
warmup_rate = 0.1
learning_rate =  16e-5
max_grad_norm = 1.0